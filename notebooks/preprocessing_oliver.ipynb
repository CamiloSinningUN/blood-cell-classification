{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images:   3%|â–Ž         | 337/10165 [03:39<1:46:53,  1.53it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_cv.layers import AugMix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = \"/kaggle/input/blood-cells/cleaned_training_set.npz\"\n",
    "\n",
    "# Load data and normalize\n",
    "data = np.load(data_path, allow_pickle=True)\n",
    "X = data['images']\n",
    "y = data['labels']\n",
    "\n",
    "# Convert to int and normalize\n",
    "X = X.astype(int)\n",
    "X = (X / 255).astype('float32')\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, stratify=y)\n",
    "\n",
    "# Define AugMix with mid-to-high severity\n",
    "augmix_layer = AugMix(value_range=(0, 1), severity=0.5, num_chains=3, chain_depth=(2, 4), alpha=1.0)\n",
    "\n",
    "# Function to apply AugMix to each image\n",
    "def augment_image(image, label):\n",
    "    aug_img = augmix_layer(image[None, ...])[0]\n",
    "    return aug_img, label\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "\n",
    "# Apply augmentation\n",
    "train_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch and prefetch\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Save the final training and validation sets as .npz files\n",
    "X_train_augmented, y_train_augmented = next(iter(train_dataset.unbatch().batch(len(X_train))))\n",
    "X_val_augmented, y_val_augmented = next(iter(val_dataset.unbatch().batch(len(X_val))))\n",
    "\n",
    "# Concatenate original and augmented data\n",
    "X_train_combined = np.concatenate((X_train, X_train_augmented.numpy()), axis=0)\n",
    "y_train_combined = np.concatenate((y_train, y_train_augmented.numpy()), axis=0)\n",
    "X_val_combined = np.concatenate((X_val, X_val_augmented.numpy()), axis=0)\n",
    "y_val_combined = np.concatenate((y_val, y_val_augmented.numpy()), axis=0)\n",
    "\n",
    "np.savez('/kaggle/working/full_and_augMix_training_data.npz', images=X_train_combined, labels=y_train_combined)\n",
    "np.savez('/kaggle/working/full_and_augMix_validation_data.npz', images=X_val_combined, labels=y_val_combined)\n",
    "\n",
    "print(\"Combined training and validation datasets saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display images\n",
    "def display_images(dataset, num_images):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(num_images):\n",
    "            ax = plt.subplot(5, 5, i + 1)\n",
    "            plt.imshow(images[i].numpy())\n",
    "            plt.title(np.argmax(labels[i].numpy()))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "# Display 25 augmented images from the training dataset\n",
    "display_images(train_dataset, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of labels in the training and validation datasets\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(np.argmax(y_train, axis=1), bins=np.arange(y_train.shape[1] + 1) - 0.5, edgecolor='black')\n",
    "plt.title('Training Set Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(np.arange(y_train.shape[1]))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.argmax(y_val, axis=1), bins=np.arange(y_val.shape[1] + 1) - 0.5, edgecolor='black')\n",
    "plt.title('Validation Set Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(np.arange(y_val.shape[1]))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
